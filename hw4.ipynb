{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will implement an audio matching system that can recognize a live performance of classical music.\n",
    "\n",
    "I have provided a skeleton of the code below, and you will fill in any sections marked with `### START CODE BLOCK ###` and `### END CODE BLOCK ###`.  Please do not change the code outside of these markers.  In particular, do not define any new functions, change the code decomposition, or modify function inputs, outputs, or default values.  Note that this code is written for ease of understanding and ease of grading, not for efficiency.\n",
    "\n",
    "Once you have completed this assignment, please run all cells in your notebook, make sure that all plots, images, and outputs are embedded in the notebook, and then submit your .ipynb file on Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partner 1 Name: Dan Fonseca\n",
    "\n",
    "Number of hours spent (Partner 1): __________\n",
    "\n",
    "Partner 2 Name: Patrick Liu\n",
    "\n",
    "Number of hours spent (Partner 2): __________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa as lb # for reference, my solutions use librosa version 0.7.2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "import glob\n",
    "import os.path\n",
    "import subprocess\n",
    "import pickle\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "#import hw4_solns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore') # to suppress warning messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Chroma Features (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first part you will implement a function that extracts chroma features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the extractChromaFeatures function, you should:\n",
    "- load the audio using librosa.core.load\n",
    "- calculate the STFT using scipy.signal.stft\n",
    "- compute the squared magnitude of STFT coefficients\n",
    "- determine the log frequency conversion matrix by calling getLogFreqConversionMatrix()\n",
    "- determine the chroma conversion matrix by calling getChromaConversionMatrix()\n",
    "- compute chroma features by applying the chroma conversion matrix\n",
    "- apply element-wise logarithmic compression by calling logCompression()\n",
    "- L2 normalize each column by calling normL2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractChromaFeatures(mp3file, sr = 22050, winsize = 2048, hop = 512, gamma = 10000):\n",
    "    '''\n",
    "    Compute chroma feature matrix on a specified audio file.\n",
    "    \n",
    "    Arguments:\n",
    "    mp3file -- path to mp3 file\n",
    "    sr -- desired sampling rate in Hz\n",
    "    winsize -- analysis window size in samples\n",
    "    hop -- hop size in samples\n",
    "    gamma -- coefficient used in log compression\n",
    "    \n",
    "    Returns:\n",
    "    F -- chroma feature matrix of size (12, M), where M is the number of audio frames.  The\n",
    "         features have logarithmic compression and each column is L2 normalized.\n",
    "    '''\n",
    "    ### START CODE BLOCK ###\n",
    "    audio, sr = lb.load(mp3file, sr=sr)\n",
    "    f, t, audio_stft = stft(audio, nperseg=winsize, noverlap=winsize-hop)\n",
    "    audio_stft_mag = np.abs(audio_stft)\n",
    "    audioLog = getLogFreqConversionMatrix(winsize, sr)\n",
    "    audioChroma = getChromaConversionMatrix(audioLog)\n",
    "    chroma_matrix = np.matmul(audioChroma, audio_stft_mag)\n",
    "    chroma_matrix = logCompression(chroma_matrix, gamma)\n",
    "    F = normL2(chroma_matrix)\n",
    "\n",
    "    ### END CODE BLOCK ###\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the log frequency spectrogram Slog, we can simply pre-multiply the one-sided spectrogram S with a matrix B.  If S has dimensions (N/2)+1 rows by M columns, then B will have 128 rows by (N/2)+1 columns.\n",
    "\n",
    "In the getLogFreqConversionMatrix function, you should:\n",
    "- determine the lower and upper bound in Hz for each pitch band for p=0, 1, ..., 127\n",
    "- determine the DFT indices that fall within the lower and upper bounds for each pitch value\n",
    "- set the appropriate indices in B to construct the log frequency conversion matrix\n",
    "\n",
    "Note that B will be a binary matrix containing only zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLogFreqConversionMatrix(N, fs):\n",
    "    '''\n",
    "    Determine the log frequency conversion matrix that can be used to pre-multiply a one-sided spectrogram\n",
    "    to get a log frequency spectrogram.\n",
    "    \n",
    "    Arguments:\n",
    "    N -- analysis window size\n",
    "    fs -- sampling rate\n",
    "    \n",
    "    Returns:\n",
    "    B -- a binary matrix of shape (128, (N/2)+1).  The log frequency spectrogram can be computed\n",
    "         by computing the matrix product of B and the spectrogram matrix.\n",
    "    '''\n",
    "    numBins = int(N/2) + 1\n",
    "    pitchMax = 128\n",
    "    B = np.zeros((pitchMax, numBins))\n",
    "    p = np.arange(pitchMax)\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    for pitch in p:\n",
    "          uppBound = 440 * 2**((pitch + 1/2 - 69)/12)\n",
    "          lowBound = 440 * 2**((pitch - 1/2 - 69)/12)\n",
    "          for k in range(numBins):\n",
    "               k_freq = k * (fs / N)\n",
    "               if k_freq >= lowBound and k_freq < uppBound:\n",
    "                    B[pitch, k] = 1\n",
    "\n",
    "    ### END CODE BLOCK ###\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_arr = np.random.rand(5, 5)\n",
    "rand_arr\n",
    "f, x, rand_arr_stft = stft(rand_arr, nperseg=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_arr_stft_mag = np.abs(rand_arr_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.35674719, 0.74985652, 0.00204299, 0.1097484 , 0.95400089,\n",
       "         0.        ],\n",
       "        [0.35674719, 0.74985652, 0.00204299, 0.1097484 , 0.95400089,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.05891843, 0.74544438, 0.81515942, 0.78508095, 0.33853106,\n",
       "         0.        ],\n",
       "        [0.05891843, 0.74544438, 0.81515942, 0.78508095, 0.33853106,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.70378011, 0.98815824, 0.39365602, 0.8988172 , 0.94444604,\n",
       "         0.        ],\n",
       "        [0.70378011, 0.98815824, 0.39365602, 0.8988172 , 0.94444604,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.8346531 , 0.09016606, 0.44579038, 0.27918742, 0.25612084,\n",
       "         0.        ],\n",
       "        [0.8346531 , 0.09016606, 0.44579038, 0.27918742, 0.25612084,\n",
       "         0.        ]],\n",
       "\n",
       "       [[0.10274118, 0.81170496, 0.44570671, 0.7197693 , 0.72273408,\n",
       "         0.        ],\n",
       "        [0.10274118, 0.81170496, 0.44570671, 0.7197693 , 0.72273408,\n",
       "         0.        ]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_arr_stft_mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate chroma features, we can simply pre-multiply the one-sided spectrogram S with a matrix W.  If S has dimension (N/2)+1 rows by M columns, then W will have 12 rows by M columns.  The matrix W can be computed by collapsing appropriate rows in the log frequency conversion matrix B.\n",
    "\n",
    "In the getChromaConversionMatrix, you should:\n",
    "- initialize W to the appropriate size\n",
    "- for each chroma value, sum across constituent pitch values\n",
    "\n",
    "Note that W will be a binary matrix containing only zeros and ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getChromaConversionMatrix(B):\n",
    "    '''\n",
    "    Determine the chroma conversion matrix that can be used to pre-multiply a one-sided spectrogram\n",
    "    to calculate chroma features.\n",
    "    \n",
    "    Arguments:\n",
    "    B -- log frequency conversion matrix\n",
    "    \n",
    "    Returns:\n",
    "    W -- a binary matrix with 12 rows and the same number of columns as B.  Chroma features can be computed\n",
    "         as the matrix product of W and the spectrogram matrix.\n",
    "    '''\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "    numBins = B.shape[1]\n",
    "    W = np.zeros((12, numBins)) # 12 pitches per octave\n",
    "    \n",
    "    # Loop over all 128 pitches (B.shape(0))\n",
    "    for pitch in range(B.shape[0]):\n",
    "        chroma = pitch % 12\n",
    "        W[chroma, :] += B[pitch, :]\n",
    "    \n",
    "    W[W>0] = 1   # why doing this\n",
    "         \n",
    "    ### END CODE BLOCK ###ffgdcdcfgbvcfgbvb\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the logCompression function, you should:\n",
    "- apply logarithmic compression ln(1 + gamma * c) to each element c.  Note that the log is with base e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logCompression(F, gamma = 10000):\n",
    "    '''\n",
    "    Apply element-wise logarithmic compression.\n",
    "    \n",
    "    Arguments:\n",
    "    F -- input matrix\n",
    "    gamma -- scalar that controls the level of compression as ln(1 + gamma * c)\n",
    "    \n",
    "    Returns:\n",
    "    Fc -- matrix of logarithmically compressed values.  Fc is of the same size as F.\n",
    "    '''\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "    Fc = np.log(1+F*gamma)\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "\n",
    "    return Fc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the normL2 function, you should:\n",
    "- normalize each column of a matrix to have unit L2 norm\n",
    "\n",
    "Make sure to implement this in a vectorized way.  Also, you will want to add a small epsilon (e.g. `1e-9`) to the denominator in case you have a column of all zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normL2(F):\n",
    "    '''\n",
    "    Normalize each column of a matrix to have unit L2 norm.\n",
    "    \n",
    "    Arguments:\n",
    "    F -- input feature matrix where each column corresponds to a single feature vector\n",
    "    \n",
    "    Returns:\n",
    "    Fnorm -- normalized feature matrix of the same shape as F, where each column has been\n",
    "             been normalized to be unit L2 norm\n",
    "    '''\n",
    "    ### START CODE BLOCK ###\n",
    "\n",
    "    norms = np.sqrt(np.sum(F**2, axis=0)) + 1e-9\n",
    "    Fnorm = F/norms\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return Fnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some sample outputs to use for debugging and verifying that your implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = getLogFreqConversionMatrix(2048, 22050)\n",
    "B[64,25:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = getChromaConversionMatrix(B)\n",
    "C[0,0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
    "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  9.21044037,  9.90353755],\n",
       "       [10.30898599, 10.59665973, 10.81979828],\n",
       "       [11.00211651, 11.15626481, 11.28979441]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logCompression(np.arange(9).reshape((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[ 0.        ,  9.21044037,  9.90353755],\n",
    "       [10.30898599, 10.59665973, 10.81979828],\n",
    "       [11.00211651, 11.15626481, 11.28979441]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = normL2(np.random.randn(5,10))\n",
    "np.sum(T * T, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "F = extractChromaFeatures('queries/chopin_alternate_query.mp3')\n",
    "plt.imshow(F[:,0:50], cmap = 'jet', origin = 'lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/sampleChroma.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Database (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will construct the database of features.\n",
    "\n",
    "In the constructDB function, you should:\n",
    "- create a python dictionary that will contain the database\n",
    "- iterate through the mp3 files in the specified directory using glob.glob\n",
    "- extract chroma features from each file\n",
    "- store the chroma feature matrix in the dictionary, where the dictionary key is a string specifying the piece name and the value is a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructDB(indir):\n",
    "    '''\n",
    "    Constructs a database containing the feature matrices for all reference tracks.\n",
    "    \n",
    "    Arguments:\n",
    "    indir -- directory containing the mp3 files to store in the database\n",
    "    \n",
    "    Returns:\n",
    "    db -- a dictionary where the key is the name of the piece and the value is its chroma feature matrix\n",
    "    '''\n",
    "    db = defaultdict(list)\n",
    "    mp3_path = f'{indir}/*.mp3'\n",
    "    mp3_files = glob.glob(mp3_path)\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "    for file in mp3_files:\n",
    "        file_name = os.path.basename(file)\n",
    "        file_chroma = extractChromaFeatures(file)\n",
    "        db[file_name] = file_chroma\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the constructDB function and save the database to file using `pickle.dump` for later use.  Note that this may take about a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():587] error: No comment text / valid description?\n",
      "[src/libmpg123/id3.c:INT123_id3_to_utf8():394] warning: Weird tag size 87 for encoding 1 - I will probably trim too early or something but I think the MP3 is broken.\n"
     ]
    }
   ],
   "source": [
    "### START CODE BLOCK ###\n",
    "ref_dir = 'references'\n",
    "db = constructDB(ref_dir)\n",
    "# print(db)\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the database to file for convenient access later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('db.pkl','wb') as f:\n",
    "    pickle.dump(db, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsequence DTW (35 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will implement functions necessary to run subsequence DTW.  The tasks you must complete are:\n",
    "- implement the computeCostMatrix_costdist function\n",
    "- implement the subsequenceDTW function\n",
    "- compare the output of your function to librosa.core.dtw to verify that they match on a single example\n",
    "- plot the cost matrix and overlay the predicted alignment path for a single example\n",
    "- listen to the query and predicted matching segment of the reference to verify that the alignment was done correctly\n",
    "- calculate the ratio between the query audio length and the matching segment length\n",
    "\n",
    "Please make sure to include all work in your notebook to get full credit!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the computeCostMatrix_cosdist function, you should:\n",
    "- compute the cosine distance cost matrix C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCostMatrix_cosdist(Fquery,Fref):\n",
    "    '''\n",
    "    Computes the cosine distance cost matrix.\n",
    "    \n",
    "    Arguments:\n",
    "    Fquery -- the query chroma feature matrix of dimension (12, # query frames), this feature\n",
    "              matrix is assumed to be L2 normalized\n",
    "    Fref -- the reference feature matrix, of dimension (12, # reference frames), this feature\n",
    "            matrix is assumed to be L2 normalized\n",
    "    \n",
    "    Returns:\n",
    "    C -- cost matrix whose (i,j)th element specifies the cosine distance between the i-th query frame\n",
    "         and the j-th reference frame\n",
    "    '''\n",
    "    \n",
    "    ### START CODE BLOCK ###\n",
    "    mul = np.dot(Fquery.T, Fref)\n",
    "    identity = np.ones(mul.shape)\n",
    "    C = identity - mul\n",
    "    ### START CODE BLOCK ###\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the subsequenceDTW function, you should:\n",
    "- initialize the cumulative cost matrix D and backtrace matrix B\n",
    "- compute the values in D and B using dynamic programming\n",
    "- call the `backtrace` function to determine the optimal path\n",
    "- construct the optimal subsequence path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequenceDTW(C, steps, weights):\n",
    "    '''\n",
    "    Find the optimal subsequence path through cost matrix C.\n",
    "    \n",
    "    Arguments:\n",
    "    C -- cost matrix of dimension (# query frames, # reference frames)\n",
    "    steps -- a numpy matrix specifying the allowable transitions.  It should be of\n",
    "            dimension (L, 2), where each row specifies (row step, col step)\n",
    "    weights -- a vector of size L specifying the multiplicative weights associated \n",
    "                with each of the allowable transitions\n",
    "                \n",
    "    Returns:\n",
    "    optcost -- the optimal subsequence path score\n",
    "    path -- a matrix with 2 columns specifying the optimal subsequence path.  Each row \n",
    "            specifies the (row, col) coordinate.\n",
    "    '''\n",
    "    D = np.zeros(C.shape)\n",
    "    B = np.zeros(C.shape, dtype=np.int8)\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    m, n = C.shape\n",
    "\n",
    "    D[0,0] = C[0,0]\n",
    "    \n",
    "    for i in range (1, m):\n",
    "        for j in range (1, n):\n",
    "            costs = []\n",
    "            for idx, (x_step, y_step) in enumerate(steps):\n",
    "                if i>=x_step and j >= y_step:\n",
    "                    costs.append((D[i-x_step, j-y_step] + C[i,j]*weights[idx], idx))\n",
    "\n",
    "            # find the min cost in this step, and its corresponding step index\n",
    "            cost = min(costs)\n",
    "            D[i,j] = cost[0]\n",
    "            B[i,j] = cost[1]\n",
    "\n",
    "    optcost = np.min(D[-1, :]) # minimum value in the last row\n",
    "    path = backtrace(D, B, steps)\n",
    "    # for row, col in path:\n",
    "    #     optcost += D[row, col]\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    path = np.array(path)\n",
    "    \n",
    "    return optcost, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the backtrace function, you should:\n",
    "- determine the coordinate of the ending point on the optimal path\n",
    "- follow the backtrace pointers and append each coordinate to `path`\n",
    "- return a list of the coordinates in the optimal subsequence path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtrace(D, B, steps):\n",
    "    '''\n",
    "    Backtraces through the cumulative cost matrix D.\n",
    "    \n",
    "    Arguments:\n",
    "    D -- cumulative cost matrix\n",
    "    B -- backtrace matrix\n",
    "    steps -- a numpy matrix specifying the allowable transitions.  It should be of\n",
    "            dimension (L, 2), where each row specifies (row step, col step)\n",
    "    \n",
    "    Returns:\n",
    "    path -- a python list of (row, col) coordinates for the optimal path.\n",
    "    '''\n",
    "\n",
    "    path = []\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    x_coordinate, y_coordinate = D.shape[0]-1, D.shape[1]-1\n",
    "\n",
    "    while x_coordinate >= 0 and y_coordinate >= 0:\n",
    "        path.append((x_coordinate, y_coordinate))\n",
    "\n",
    "        step_idx = B[x_coordinate, y_coordinate] # how to use B[x_coordinate, y_coordinate]. What does it mean by 2, 1, 0.....\n",
    "        # print(step_idx)\n",
    "        x_step, y_step = steps[step_idx]\n",
    "        x_coordinate -= x_step\n",
    "        y_coordinate -= y_step \n",
    "    \n",
    "\n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if your implementation is correct, verify that your function's output matches the output of librosa.core.dtw on the following example (please do not change the parameters below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryfile = 'queries/beethoven_alternate_query.mp3'\n",
    "reffile = 'references/beethoven.mp3'\n",
    "steps = np.array([2, 1, 1, 2, 1, 1]).reshape((3,2))\n",
    "weights = [1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fquery = extractChromaFeatures(queryfile)\n",
    "Fref = extractChromaFeatures(reffile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   8, 2918],\n",
       "        [   6, 2917],\n",
       "        [   4, 2916],\n",
       "        [   2, 2915],\n",
       "        [   0, 2914]]),\n",
       " 1.8576943526977634)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D, wp = lb.sequence.dtw(X=Fquery, Y=Fref, step_sizes_sigma=steps, weights_mul=weights, metric = 'cosine', subseq=True)\n",
    "wp[-5:], np.min(D[-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   8, 5268],\n",
       "        [   6, 5267],\n",
       "        [   4, 5266],\n",
       "        [   2, 5265],\n",
       "        [   0, 5264]]),\n",
       " 0.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run your own implementation of subsequence DTW and verify that the outputs match\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "costMatrix = computeCostMatrix_cosdist(Fquery, Fref)\n",
    "optcost, path = subsequenceDTW(costMatrix, steps, weights)\n",
    "path[-5:], optcost\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cost matrix as an image and overlay the predicted alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the query and the predicted matching segment of the reference.  You can use IPython.display.Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to query\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listen to matching segment of reference\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the ratio of the query length to the matching segment length.  This gives an overall sense of how similar or different the tempos are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will put all the pieces together to implement an audio matching system and measure its accuracy.  You must do the following:\n",
    "- implement runBenchmark function\n",
    "- run the benchmark and display the accuracy of your system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the runBenchmark function, you should:\n",
    "- iterate through the query files in the specified directory\n",
    "- extract features on the query\n",
    "- compute the match score of each piece in the database using subsequence DTW\n",
    "- check if the predicted piece is correct\n",
    "\n",
    "To speed up your experiment, you may use `lb.sequence.dtw` in place of your own subsequenceDTW implementation.  You should compute the cost matrix using your `computeCostMatrix_cosdist` function, and then pass the cost matrix to `lb.sequence.dtw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBenchmark(d, indir, steps, weights, shorten = None):\n",
    "    '''\n",
    "    Runs a benchmark on a given set of queries and returns the accuracy of the system.\n",
    "    \n",
    "    Arguments:\n",
    "    d -- database of chroma feature matrices\n",
    "    indir -- directory containing query mp3 files\n",
    "    steps -- matrix specifying allowable transitions in the subsequence DTW, size (L, 2)\n",
    "    weights -- vector of length L specifying the multiplicative weights of each transition\n",
    "    shorten -- a float between 0 and 1 specifying what fraction of the query to use.  For example, \n",
    "               when shorten = .5, only the first 50% of the features will be used.\n",
    "               \n",
    "    Returns:\n",
    "    accuracy -- the fraction of queries that were identified correctly\n",
    "    '''\n",
    "\n",
    "    ### START CODE BLOCK ###\n",
    "    \n",
    "    ### END CODE BLOCK ###\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the benchmark and print out the system accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you will run additional experiments to gain more intuition about how subsequence DTW works.  You should do the following:\n",
    "- Run a set of experiments that varies two different parameters: the length of the audio query and the DTW transition weights.  The allowable transitions should be fixed to {(1,1), (1,2), (2,1)}.\n",
    "- Create a plot that shows how accuracy changes for the following query lengths: 3 sec, 2 sec, 1 sec, .75 sec, .5 sec, .25 sec.  Your plot should also compare the following two weighting schemes: `{1,1,1}` and `{1,1,2}`.  This will require you to run your benchmark 12 times with different settings.\n",
    "- Describe which weighting scheme is better for very short queries and provide an intuitive explanation for why that weighting scheme should be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run series of benchmarks\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot of results\n",
    "\n",
    "### START CODE BLOCK ###\n",
    "\n",
    "### END CODE BLOCK ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "E207_Spr24",
   "language": "python",
   "name": "e207_spr24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
